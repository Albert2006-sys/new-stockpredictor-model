Person 1: The Quant
Your Primary Objective: You are the architect of the project's intelligence. Your world is data, features, and the machine learning models. You are responsible for building a robust, automated training pipeline that produces high-quality prediction models every night.

File Ownership:

backend/utils/database_manager.py

backend/utils/corporate_action_handler.py

backend/ingestion/price_ingestor.py

backend/ml_models/feature_engineering.py

backend/ml_models/train_model.py

backend/ml_models/validate_model.py

backend/monitoring/drift_monitor.py

README.md (Technical architecture & backend setup sections)

Day-by-Day Plan for The Quant
Day 1 (Thu, Sep 4): The Data Core

Key Focus: Establish the database and the primary data feed.

Checklist:

[ ] Set up the entire project folder structure and initialize the Git repository.

[ ] Write backend/utils/database_manager.py to handle all TimescaleDB connections.

[ ] Write backend/ingestion/price_ingestor.py. Get it running in a loop, fetching data for the 20 stocks and successfully writing it to the database.

[ ] SYNC: Confirm with Person 2 that the database is accessible and the table schema is correct.

Day 2 (Fri, Sep 5): Data Integrity & Features

Key Focus: Make the data trustworthy and start building features.

Checklist:

[ ] Write backend/utils/corporate_action_handler.py to adjust historical prices.

[ ] Write backend/ml_models/feature_engineering.py. Implement the calculation for all technical indicators.

[ ] Create a sample CSV of feature-rich data to share with Person 2.

[ ] SYNC: Finalize the exact feature set and column names with Person 2.

Day 3 & 4 (Sat, Sep 6 - Sun, Sep 7): The ML Marathon

Key Focus: Build and train the deep learning models. This is your most intensive period.

Checklist:

[ ] In backend/ml_models/train_model.py:

[ ] Implement the Triple-Barrier Method to create the price movement labels.

[ ] Build, train, and evaluate the LSTM model.

[ ] Build, train, and evaluate the Transformer model.

[ ] Add the logic to convert and save both trained models to the TensorFlow Lite (.tflite) format.

[ ] DELIVER: Provide the first versions of lstm_v1.tflite and transformer_v1.tflite to Person 2.

Day 5 (Mon, Sep 8): Validation & Automation

Key Focus: Create the system that decides if a new model is good enough.

Checklist:

[ ] Write backend/ml_models/validate_model.py. This script must be able to load two models, test them on a validation set, and declare a winner.

[ ] Implement the logic for the validation script to update the config/model_config.json file.

[ ] SYNC: Explain the validation logic to Person 2 so they understand how models will be swapped.

Day 6 (Tue, Sep 9): Monitoring & Health Checks

Key Focus: Build the system's immune system.

Checklist:

[ ] Write backend/monitoring/drift_monitor.py.

[ ] Implement the logic for the monitor to trigger a rollback by rewriting the model_config.json file.

[ ] Write the master script for the daily retraining process and set it up as a cron job.

Day 7 (Wed, Sep 10): Testing & Documentation

Key Focus: Ensure the entire backend pipeline runs flawlessly overnight.

Checklist:

[ ] Manually trigger the full retraining and validation pipeline. Debug any issues.

[ ] Assist Person 2 with any backend-related bugs found during full-system testing.

[ ] Write the detailed technical sections of the README.md.



1. backend/utils/database_manager.py
Core Objective: To create a centralized, reusable, and robust interface for all database interactions. No other file should contain raw database connection logic. This abstraction ensures consistency and makes future changes (e.g., changing credentials) trivial.

Key Components & Logic:

create_db_engine(): This function reads the database credentials (DB_HOST, DB_USER, DB_PASSWORD, DB_NAME, DB_PORT) from config/settings.py. It then constructs the database connection URL and uses sqlalchemy.create_engine() to create and return a connection pool engine object. This engine is what other parts of the application will use.

write_to_db(df, table_name, engine, if_exists='append'): This function takes a pandas DataFrame, a target table name, and the engine object. It uses the powerful df.to_sql() method to write the data. It must be configured to handle existing tables gracefully, usually by appending new data.

read_from_db(query, engine): This function takes a SQL query string and the engine object. It uses pd.read_sql(query, engine) to execute the query and return the results neatly packaged as a pandas DataFrame.

Inputs: Database credentials from config/settings.py.

Outputs: A SQLAlchemy engine object; functions for reading/writing data.

Critical Precautions & Mindset:

Singleton Pattern: Think of the engine object as a singleton. It should be created once and passed around. Avoid creating new engines for every single query.

Security: This file handles sensitive credentials. Ensure it reads them from the config and never has them hardcoded.

Robustness: The connection logic should include basic error handling in case the database server is not available on startup.

2. backend/utils/corporate_action_handler.py
Core Objective: To maintain the integrity of historical price data by programmatically adjusting for corporate actions like stock splits and dividends. This prevents the ML models from interpreting these events as massive, unexplained price volatility.

Key Components & Logic:

fetch_corporate_actions(ticker_list): A function that runs daily (before market open). It queries yfinance for each stock's .splits and .dividends for the upcoming day. If any are found, it stores them in a dedicated database table (e.g., corporate_actions).

adjust_prices_for_splits(db_engine): A function that reads the corporate_actions table for any pending splits. For each split, it must:

Fetch all historical price data for that stock before the split date.

Apply the standard split adjustment formula (e.g., for a 2-for-1 split, all historical prices are divided by 2, and volumes are multiplied by 2).

Overwrite the old historical prices with the newly adjusted ones.

adjust_prices_for_dividends(db_engine): Similar logic for dividends, which also causes a price drop. The adjustment is typically made to prevent the model from seeing a dividend payment as a negative market event.

Inputs: Raw historical price data from the database.

Outputs: Adjusted historical price data written back to the database.

Critical Precautions & Mindset:

Idempotency: Your script must be designed so that running it multiple times does not apply the same adjustment repeatedly. It should have a mechanism to mark an action as "processed."

Accuracy: The financial formulas for these adjustments must be precise. A small error can corrupt your entire dataset. Double-check the formulas against reliable financial sources.

Atomicity: In a production system, these updates would be done within a database transaction to ensure that the operation either completes fully or not at all, preventing partial data corruption.

3. backend/ingestion/price_ingestor.py
Core Objective: To be the real-time heartbeat of the system. This is a continuously running service dedicated solely to fetching and storing 1-minute price data for the 20 target stocks during market hours.

Key Components & Logic:

Main Loop: An infinite while True loop that runs the ingestion logic.

Polling Logic: Inside the loop, it iterates through the list of 20 tickers and uses yfinance to fetch the latest available price data.

Rate Limiting: After each full loop, it must include a time.sleep(30) (or similar) to avoid overwhelming the yfinance service and getting IP-banned.

Stateful Gap Detection: The script needs to maintain a dictionary in memory, mapping each ticker to the timestamp of the last data point it successfully wrote. When it fetches new data, it compares the new timestamp to the last saved one. If there's a gap of more than a minute, it adds the missing (ticker, start_time, end_time) to a "backfill queue."

Backfill Process: A separate function, ideally run after market hours, that processes the backfill queue, fetching the historical data for the missed periods to ensure the dataset is complete for overnight training.

Error Handling: The loop must be wrapped in a robust try-except block to handle network errors or API failures without crashing the entire service. It should log the error and continue.

Inputs: A list of 20 stock tickers.

Outputs: Minute-by-minute price data written to the price_data hypertable in TimescaleDB.

Critical Precautions & Mindset:

Resilience is Key: This script is the foundation of the real-time system. It must be designed to run for days without crashing. Logging is not optional; it's essential for debugging.

Respect the API: Do not be greedy with the polling interval. A polite, consistent polling rate is more reliable in the long run than an aggressive one that gets you blocked.

4. backend/ml_models/feature_engineering.py
Core Objective: To transform raw, noisy time-series data into a rich, informative feature set that the deep learning models can learn from. This is where a significant portion of the model's predictive "edge" is created.

Key Components & Logic:

create_features(raw_price_df): A primary function that takes the raw price DataFrame from the database.

Technical Indicators: Uses libraries like pandas_ta to calculate a wide array of indicators:

Momentum: RSI (e.g., 14-period), MACD.

Trend: EMA (e.g., 12-period, 26-period).

Volatility: Bollinger Bands.

Time-Based Features: Extracts features from the timestamp itself, which can capture intraday patterns:

minute_of_hour

hour_of_day

day_of_week

Lagged Features: Creates features based on past values (e.g., the price change over the last 5 minutes).

Inputs: Raw price data from TimescaleDB.

Outputs: A pandas DataFrame with many new feature columns. This DataFrame is used directly by the train_model.py script.

Critical Precautions & Mindset:

Avoid Lookahead Bias: When creating features like rolling averages, ensure you are only using past data. A "centered" moving average that uses future data will leak information and create a deceptively accurate model that fails in live trading.

Feature Scaling: All features must be normalized (e.g., using MinMaxScaler from scikit-learn) before being fed into a neural network. The scaling parameters must be "fit" on the training data only and then "transformed" on the validation/test data.

5. backend/ml_models/train_model.py
Core Objective: To orchestrate the entire machine learning training process. This script is the heart of the "Quant" role. It takes in data, applies labels, trains two sophisticated models, and saves the final, deployable artifacts.

Key Components & Logic:

Data Loading: Loads a large historical dataset from the database using database_manager.

Label Creation:

Implements the Triple-Barrier Method logic. This is a critical function that creates the 1 (Up), -1 (Down), and 0 (Neutral) labels that the models will predict. This is your prediction target.

Data Preprocessing:

Calls the create_features function from feature_engineering.py.

Reshapes the data into sequences (e.g., samples of 60 minutes) required by LSTMs and Transformers.

Model Building: Defines the architecture for both the LSTM and the Transformer models using the TensorFlow/Keras API. The final layer must be a Dense layer with 3 neurons and a softmax activation function.

Training: Compiles and trains both models on the prepared data.

Conversion to TFLite: After training, it takes the final TensorFlow models and uses the TFLiteConverter to create lightweight, optimized .tflite files for fast inference.

Inputs: Historical price data, feature engineering logic.

Outputs: Two trained model files: lstm_vX.tflite and transformer_vX.tflite.

Critical Precautions & Mindset:

Time-Based Split: You must split your data chronologically. Train on an older period (e.g., Jan-July) and validate on a more recent period (e.g., August). A random split will destroy the model's validity.

Prevent Overfitting: Use techniques like Dropout layers in your model architecture and Early Stopping callbacks during training to prevent the models from simply memorizing the training data.

6. backend/ml_models/validate_model.py
Core Objective: To act as the automated quality gatekeeper. This script ensures that a newly trained model is only deployed if it is demonstrably better than the one currently in production.

Key Components & Logic:

Model Loading: Loads the new "Challenger" models (just trained) and the old "Champion" models (the paths are in model_config.json).

Validation Set: Loads a dedicated, unseen validation dataset (e.g., the most recent week of data).

Performance Comparison: Evaluates both the Champion and Challenger models on the validation set using key metrics (e.g., F1-Score, Precision for the "UP" and "DOWN" classes).

Decision Logic: If the Challenger's performance is better than the Champion's by a certain threshold (to prevent random churn), it is declared the new Champion.

Update Config: If there is a new champion, this script overwrites the config/model_config.json file with the path to the new model file.

Inputs: The paths to the old and new model files, and a validation dataset.

Outputs: An updated model_config.json file.

Critical Precautions & Mindset:

Be Objective: The validation process must be fully automated. Do not manually intervene. The metrics should decide the winner.

Stability over Churn: It's often better to keep a slightly less performant but stable model than to constantly swap to new models that might be overfit to the most recent data. The threshold for declaring a new champion should not be trivial.

7. backend/monitoring/drift_monitor.py
Core Objective: To be the system's early warning system. It runs in parallel to the main application, watching for signs that the live market is behaving differently from the data the model was trained on.

Key Components & Logic:

Live Data Monitoring: Connects to the database and monitors the most recent incoming price and feature data.

Drift Detection:

Data Drift: Calculates simple statistics (e.g., mean, standard deviation) on a rolling window of live data (e.g., last hour) and compares them to the statistics of the training data. If they diverge significantly, it triggers a data drift alert.

Concept Drift: Monitors the confidence (probability) of the live predictions being made by the API. If the model's confidence consistently drops, it triggers a concept drift alert.

Rollback Trigger: If a severe drift is detected and persists, this script will enact the rollback strategy: it will rewrite the model_config.json file to point to the previous stable version of the model.

Inputs: Live data from the database, live predictions.

Outputs: Logs, alerts, and potentially a modified model_config.json.

Critical Precautions & Mindset:

False Alarms: Be careful not to make the drift detection too sensitive, or it will trigger alerts on normal market volatility. The thresholds need to be set carefully.

This is a Safety Net: This service is your protection against the model failing silently in a changing market. It's a critical component for building trust in the system.